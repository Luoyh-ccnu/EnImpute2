% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/EnImpute2.R
\name{EnImpute2}
\alias{EnImpute2}
\title{Run EnImpute2 on a raw read count matrix}
\usage{
EnImpute2(
  count,
  scale.factor = 10000,
  trim = 0.3,
  threshold = 0.7,
  ALRA = TRUE,
  DCA = TRUE,
  DrImpute = TRUE,
  knn_smooth = TRUE,
  MAGIC = TRUE,
  SAVER = TRUE,
  scImpute = TRUE,
  scNPF = TRUE,
  SCRABBLE = TRUE,
  scRMD = TRUE,
  scTSSR = TRUE,
  scTSSR2 = TRUE,
  SDImpute = TRUE,
  VIPER = TRUE,
  zinbwave = TRUE,
  ALRA.k = 0,
  ALRA.q = 10,
  DCA.normtype = "zheng",
  DCA.type = "zinb-conddisp",
  DCA.l2 = 0,
  DCA.l1 = 0,
  DCA.l2enc = 0,
  DCA.l1enc = 0,
  DCA.ridge = 0,
  DCA.gradclip = 5,
  DCA.activation = "relu",
  DCA.hiddensize = "64,32,64",
  DCA.hyper = FALSE,
  DCA.hypern = 1000,
  DrImpute.ks = 10:15,
  DrImpute.dists = c("spearman", "pearson"),
  DrImpute.method = "mean",
  DrImpute.cls = NULL,
  knn_smooth.k = 10,
  MAGIC.k = 10,
  MAGIC.alpha = 15,
  MAGIC.t = "auto",
  MAGIC.npca = 20,
  MAGIC.t.max = 20,
  MAGIC.knn.dist.method = "euclidean",
  MAGIC.n.jobs = 1,
  SAVER.do.fast = TRUE,
  SAVER.ncores = 1,
  SAVER.size.factor = NULL,
  SAVER.npred = NULL,
  SAVER.null.model = FALSE,
  SAVER.mu = NULL,
  scImpute.drop_thre = 0.5,
  scImpute.Kcluster = 5,
  scImpute.labeled = FALSE,
  scImpute.labels = NULL,
  scImpute.genelen = NULL,
  scImpute.ncores = 1,
  scNPF.network = "context",
  scNPF.gamma = 0.5,
  scNPF.qt.gene = 0.4,
  scNPF.qt.cell = 0.5,
  scNPF.nThreads = 1,
  SCRABBLE.parameter = c(1, 1e-06, 1e-04),
  scRMD.tau = NULL,
  scRMD.lambda = NULL,
  scRMD.candidate = 0.05,
  scTSSR.lambda1 = NULL,
  scTSSR.lambda2 = 1e+10,
  scTSSR.initA = NULL,
  scTSSR.initB = NULL,
  scTSSR.percent = 0.05,
  scTSSR.MAX_ITER = 4,
  scTSSR.ABSTOL = 0.001,
  scTSSR.learning_rate = 1e-04,
  scTSSR.epochs = 100,
  scTSSR.batch_size = 128,
  scTSSR.run_batch = TRUE,
  scTSSR.verbose = TRUE,
  scTSSR.estimates.only = FALSE,
  scTSSR2.k.gene = NULL,
  scTSSR2.k.cell = NULL,
  scTSSR2.W = NULL,
  scTSSR2.lambda = 256,
  scTSSR2.percent = 0,
  scTSSR2.ncores = 1,
  scTSSR2.MAX.ITER = 4,
  scTSSR2.ABSTOL = 0.001,
  scTSSR2.learning.rate = 1e-04,
  scTSSR2.epochs = 100,
  scTSSR2.verbose = TRUE,
  scTSSR2.estimates.only = TRUE,
  SDImpute.do.nor = FALSE,
  SDImpute.do.log = TRUE,
  SDImpute.criterion = "asw",
  SDImpute.krange = c(5:15),
  SDImpute.k = 5,
  SDImpute.M = 15,
  SDImpute.T = 0.5,
  VIPER.num = 5000,
  VIPER.percentage.cutoff = 0.1,
  VIPER.minbool = FALSE,
  VIPER.alpha = 0.5,
  zinbwave.nb.repeat.initialize = 2,
  zinbwave.maxiter.optimize = 25,
  zinbwave.stop.epsilon.optimize = 1e-04
)
}
\arguments{
\item{count}{raw read count matrix. The rows correspond to genes and the columns correspond to cells.}

\item{scale.factor}{scale factor used to re-scale the imputed results generated by
different individual methods. Default is 10000.}

\item{trim}{specifies the fraction (between 0 and 0.5)  of observations to be trimmed
from each end before the mean is computed. Default is 0.3.}

\item{ALRA}{a boolean variable that defines whether to impute the raw data using the ALRA method.
Default is TRUE.}

\item{DCA}{a boolean variable that defines whether to impute the raw data using the DCA method.
Default is TRUE.}

\item{DrImpute}{a boolean variable that defines whether to impute the raw data using the DrImpute method.
Default is "TRUE".}

\item{knn_smooth}{a boolean variable that defines whether to impute the raw data using the knn_smooth method.
Default is "TRUE".}

\item{MAGIC}{a boolean variable that defines whether to impute the raw data using the MAGIC method.
Default is TRUE.}

\item{SAVER}{a boolean variable that defines whether to impute the raw data using the SAVER method.
Default is TRUE.}

\item{scImpute}{a boolean variable that defines whether to impute the raw data using the scImpute method.
Default is TRUE.}

\item{scNPF}{a boolean variable that defines whether to impute the raw data using the scNPF method.
Default is TRUE.}

\item{SCRABBLE}{a boolean variable that defines whether to impute the raw data using the SCRABBLE method.
Default is TRUE.}

\item{scRMD}{a boolean variable that defines whether to impute the raw data using the scRMD method.
Default is TRUE.}

\item{scTSSR}{a boolean variable that defines whether to impute the raw data using the scTSSR method.
Default is TRUE.}

\item{scTSSR2}{a boolean variable that defines whether to impute the raw data using the scTSSR2 method.
Default is TRUE.}

\item{SDImpute}{a boolean variable that defines whether to impute the raw data using the SDImpute method.
Default is TRUE.}

\item{VIPER}{a boolean variable that defines whether to impute the raw data using the VIPER method.
Default is TRUE.}

\item{zinbwave}{a boolean variable that defines whether to impute the raw data using the zinbwave method.
Default is TRUE.}

\item{ALRA.k}{the rank of the rank-k approximation in ALRA. Set to 0 for automated choice of k.
Default is 0.}

\item{ALRA.q}{the number of power iterations in randomized SVD used by ALRA. Default is 10.}

\item{DCA.normtype}{a string variable specifying the type of size factor estimation in DCA.
Possible values: "deseq", "zheng". Default is "zheng".}

\item{DCA.type}{a string variable specifying type of autoencoder in DCA. Possible values:
"normal", "poisson", "nb", "nb-shared", "nb-conddisp", "nb-fork", "zinb", "zinb-shared", "zinb-conddisp",
"zinb-fork". Default is "zinb-conddisp".}

\item{DCA.l2}{a real number specifying the L2 regularization coefficient in DCA.  Default is 0.}

\item{DCA.l1}{a real number specifying the L1 regularization coefficient in DCA.  Default is 0.}

\item{DCA.l2enc}{a real number specifying the encoder-specific L2 regularization coefficient in DCA.
Default is 0.}

\item{DCA.l1enc}{a real number specifying the encoder-specific L1 regularization coefficient in DCA.
Default is 0.}

\item{DCA.ridge}{a real number specifying the L2 regularization coefficient for dropout probabilities
in DCA. Default is 0.}

\item{DCA.gradclip}{a real number specifying the Clip grad values in DCA. Default is 5.}

\item{DCA.activation}{a string value specifying the activation function of hidden unit in DCA. Default is "relu".}

\item{DCA.hiddensize}{a string vector specifying the size of hidden layers in DCA. Default is "64,32,64".}

\item{DCA.hyper}{a logical value specifying whether hyperparameter search is performed in DCA.}

\item{DCA.hypern}{an integer specifying the number of samples drawn from hyperparameter distributions
during optimization in DCA. Default is 1000.}

\item{DrImpute.ks}{an integer vector specifying the number of cell clustering groups in DrImpute.
Default is 10:15.}

\item{DrImpute.dists}{a string vector specifying the distance metrics in DrImpute. Default is
c("spearman", "pearson").}

\item{DrImpute.method}{a string specifying the method used for imputation in DrImpute. Use "mean"
for mean imputation, "med" for median imputation.}

\item{DrImpute.cls}{a matrix specifying the clustering information manually provided by users in DrImpute.
The rows represent different clusterings, and the columns represent cells. Default is NULL,
which means the user do not provide the clustering information.}

\item{MAGIC.k}{an integer specifying the number of nearest neighbors on which to build kernel in MAGIC.
Default is 10.}

\item{MAGIC.alpha}{an integer specifying the decay rate of kernel tails in MAGIC. Default is 15.}

\item{MAGIC.t}{an integer specifying the diffusion time for the Markov Affinity Matrix in MAGIC.
Default is "auto". For detail about the approach to set paramter t automatically,
please refer to the reference.}

\item{MAGIC.npca}{an integer specifying the number of PCA components in MAGIC.
Default is 20.}

\item{MAGIC.t.max}{an integer specifying the maximum value of t to test for automatic t selection in MAGIC.
Default is 20.}

\item{MAGIC.knn.dist.method}{a string value specifying the metric for building kNN graph in MAGIC.
Recommended values: "euclidean", "cosine". Default is "euclidean".}

\item{MAGIC.n.jobs}{an integer specifying the number of jobs used for computation in MAGIC. If -1 all CPUs are used.
If 1 is given, no parallel computing code is used at all. For n.jobs below -1, (n.cpus + 1 + n.jobs)
are used. Thus for n.jobs = -2, all CPUs but one are used.}

\item{SAVER.do.fast}{a boolean variable specifying whether the prediction step is
approximated in SAVER. Default is TRUE.}

\item{SAVER.ncores}{number of cores to use in SAVER. Default is 1.}

\item{SAVER.size.factor}{a vector of cell size specifying the normalization factors in SAVER.
If the data is already normalized or normalization is not desired, set size.factor = 1.
Default uses mean library size normalization.}

\item{SAVER.npred}{number of genes for regression prediction in SAVER. Selects the top npred genes in
terms of mean expression for regression prediction. Default is all genes.}

\item{SAVER.null.model}{a boolean variable specifying whether to use mean gene expression as prediction
in SAVER. Default is FALSE}

\item{SAVER.mu}{matrix of prior means in SAVER.}

\item{scImpute.drop_thre}{a number (between 0 and 1) specifying the threshold on dropout probability in scImpute.
Default is 0.5.}

\item{scImpute.Kcluster}{an integer specifying the number of cell subpopulations in scImpute. Default is 10.}

\item{scImpute.labeled}{a boolean variable indicating whether cell type information is given in scImpute. Default is FALSE.}

\item{scImpute.labels}{a character vector specifying the cell type in scImpute. Only needed when \code{labeled = TRUE}.
Default is NULL}

\item{scImpute.genelen}{an integer vector giving the length of each gene in scImpute.  Default is NULL.}

\item{scImpute.ncores}{an integer specifying the number of cores used for parallel computation in scImpute. Default is 1.}

\item{scNPF.network}{A adjacency matrix contation gene-gene interaction network. User can use priori mode or context mode. For priori mode, users can use publicly available molecular networks. In this package, we provided three human gene-gene interaction networks, including String, HumanNet and an integrated network. For context mode (default), a context-specific gene-gene network is constructed from the scRNA-seq data by WGCNA package.}

\item{scNPF.gamma}{A number between 0 and 1 (default: 0.5). gamma is the trade-off between prior information and network diffusion, governing the distance that a signal is allowed to diffuse through the network during smoothing. The specific value of gamma has little effect on the results of network propagation over a sizable range.}

\item{scNPF.qt.gene}{A numeric value between 0 and 1 (default: 0.4) indicating the top percent of expressed genes to be reserved for buliding a context-specific gene-gene network. Used only if network = "context".}

\item{scNPF.qt.cell}{A numeric value between 0 and 1 (default: 0.5) indicating the top percent of expressed cells to be reserved for buliding a context-specific gene-gene network. Used only if network = "context".}

\item{scNPF.nThreads}{The number of cores to use. Default is 1.}

\item{SCRABBLE.parameter}{the vector of parameters. The first parameter is the value of alpha in the mathematical model , the second one is the value of beta in the mathematical model.}

\item{scRMD.tau}{a non-negative real number specifying the tuning parameter to penalize the sparse term. Default is NULL.}

\item{scRMD.lambda}{a non-negative real number specifying the tuning parameter to penalize the row rank term. Default is NULL.}

\item{scRMD.candidate}{a real number (0 to 1) specifying the cutoff for candidate drop out. Default is 0.05.}

\item{scTSSR.lambda1}{Tuning parameter to facilitate feature selection and regularization.}

\item{scTSSR.lambda2}{Tuning parameter to penalize the diagonal elements of the parameter to eliminate the trivial solution of representing an expression level as a linear combination of itself.}

\item{scTSSR.initA}{The initionlization of A. The elements of A represent the similarities between genes.}

\item{scTSSR.initB}{The initionlization of B. The elements of B represent the similarities between cells.}

\item{scTSSR.percent}{The expression count matrix is preprocessed by filtering out the genes expressed in at most percent*100\% of the cells.}

\item{scTSSR.MAX_ITER}{Maximum iteration of the external circulation of scTSSR.}

\item{scTSSR.ABSTOL}{Absolute tolerance of the external circulation.}

\item{scTSSR.learning_rate}{A hyper-parameter that controls the speed of adjusting the weights of the network with respect to the loss gradient.}

\item{scTSSR.epochs}{The number of the entire training set going through the entire network.}

\item{scTSSR.batch_size}{The number of examples that are fed to the algorithm at a time.}

\item{scTSSR.run_batch}{Whether to use batch or to set the number of all the samples as the value of the batch size. Default is TRUE.}

\item{scTSSR.verbose}{Whether to output the value of metrics at the end of each epoch. Default is TRUE.}

\item{scTSSR2.k.gene}{A hyper-parameter that controls the sparsity level of the estimated coefficient matrices, A1 and A2. Default is k_gene = min(100, m/30).}

\item{scTSSR2.k.cell}{A hyper-parameter that controls the sparsity level of the estimated coefficient matrices, B1 and B2. Default is k_cell = min(100, n/30).}

\item{scTSSR2.W}{A weight matrix with element W_gc denotes the non-dropout probability of the expression level of gene g in cell c. Default is W_gc=X_gc/max(X_gc).}

\item{scTSSR2.lambda}{Ridge penalty parameter. Default is 256.}

\item{scTSSR2.percent}{The expression count matrix is preprocessed by filtering out the genes expressed in at most percent*100\% of the cells. Default is 0.05.}

\item{scTSSR2.ncores}{Number of cores to use. Default is 1.}

\item{scTSSR2.MAX.ITER}{Maximum iteration of the external circulation of scTSSR2. Default is 4.}

\item{scTSSR2.ABSTOL}{Absolute tolerance of the external circulation. Default is 1e-3.}

\item{scTSSR2.learning.rate}{A hyper-parameter that controls the speed of adjusting the weights of the network with respect to the loss gradient. Default is 0.0001.}

\item{scTSSR2.epochs}{The number of the entire training set going through the entire network. Default is 100.}

\item{scTSSR2.verbose}{Whether to output the value of metrics at the end of each epoch. Default is TRUE.}

\item{SDImpute.do.nor}{Logical. If TRUE, the data is Normalized.}

\item{SDImpute.do.log}{Logical. If TRUE, the input will take log of data.}

\item{SDImpute.criterion}{One of "asw" or "ch". Determines whether average silhouette width or Calinski-Harabasz is applied.}

\item{SDImpute.krange}{Integer vector. Numbers of clusters which are to be compared by the average silhouette width criterion. Note: average silhouette width and Calinski-Harabasz can't estimate number of clusters nc=1.}

\item{SDImpute.k}{Integer. The number of cell clusters. This parameter can be determined based on prior knowledge or clustering result of raw data.}

\item{SDImpute.M}{Integer. The number of nearest neighbors.When the number of nearest neighbors for each cell is small, the parameter M should not be too large to guarantee that it makes sense. In general, this parameter is set to an integer between 10 and 30.}

\item{SDImpute.T}{Numeric between 0 and 1. The dropout probability candidate threshold which controls the degree of imputation to the gene expression matrix. The recommended value of parameter T is 0.5.}

\item{VIPER.num}{The number of random sampled genes used to fit the penalized regression model to identify the set of candidate cells. The default value is 5000. If gene number p in the dataset is less than specified num, numwill be set as 0.8*p.}

\item{VIPER.percentage.cutoff}{To reduce the influence of missing values in the weight estimation, the nonnegative regression model is fitted using genes with a zero rate less than a certain threshold. The default value is 0.1 (10 percent).}

\item{VIPER.minbool}{The criteria used to select the penalty levellambda in the penalized regression model. VIPER calls cv.glmnet() in glmnet to perform fitting cross validation. Two penalty levels are available for selection: lambda.min, the value of lambda that gives minimum mean cross-validated error, and lambda.1se, the value of lambda that gives the most regularized model such that error is within one standard error of the minimum. The default is lambda.1se, i.e., minbool = FALSE.}

\item{VIPER.alpha}{The elastic net mixing parameter. The default value is 1, which is equivalent to a lasso model.}

\item{zinbwave.nb.repeat.initialize}{Number of iterations for the initialization of beta_mu and gamma_mu.}

\item{zinbwave.maxiter.optimize}{maximum number of iterations for the optimization step (default 25).}

\item{zinbwave.stop.epsilon.optimize}{stopping criterion in the optimization step, when the relative gain in likelihood is below epsilon (default 0.0001).}
}
\value{
a list with the following components
\item{\code{count.EnImpute2.log}}{Imputed count matrix generated by EnImpute2 (log scale).}
\item{\code{count.EnImpute2.exp}}{Imputed count matrix generated by EnImpute2 (exp scale).}
\item{\code{count.imputed.individual.exp}}{Imputed count matrices generated by different individual imputation methods (exp scale).}
\item{\code{Methods.used}}{The individual methods used by EnImpute.}
}
\description{
This function is implemented to perform EnImpute2 on a raw read count matrix. EnImpute2 is an ensemble
learning-based method for imputing dropout values in scRNA-seq data which is a refinement of EnImpute which
integrates eighteen state-of-the-art methods: ALRA,DCA,DrImpute,knn_smooth, MAGIC,SAVER,
scImpute, scNPF,SCRABBLE,scRMD,scTSSR,scTSSR2,SDImpute,VIPER and zinbwave. EnImpute2 first runs the
fifteen individual imputation methods, and then use the trimmed mean of the imputed values generated
by different individual methods as a gold standard result.Then EnImpute2 converts all imputation matrixs into different vectors by columns
and calculate the Pearson correlation coefficients between eighteen methods’ imputation results and the gold standard result.
Finally EnImpute2 utilizes bcp package to sort out the most suitable methods for the data and takes the weighted average
(regarding Pearson correlation coefficients as weights)of them as the final result.This function depends on the follwing R package:
DrImpute, Rmagic, SAVER, scImpute, WGCNA,scNPF,SCRABBLE,scRMD,scTSSR,scTSSR2,SDImpute,VIPER,zinbwave,rsvd,bcp,reticulate. These packages will be automatically installed along
with EnImpute2. EnImpute2 also depends on the following seven Python packages: DCA,MAGIC,scTSSR,scTSSR2. Before
installing the R package EnImpute2, please install the seven Python packages following the corresponding
readme files, and check whether they can be run from the command line.
}
\examples{

data("baron")
result <- EnImpute2(baron$count.samp)
}
\author{
Yu-Heng Luo  <luoyuheng@mail.ccnu.edu.cn>
}
